# Law_Agent

# å¯¼å…¥å¿…è¦çš„åº“
import streamlit as st # åˆ›å»ºç½‘é¡µåº”ç”¨ç•Œé¢
import os  # è¯»å–ç¯å¢ƒå˜é‡
from langchain_core.output_parsers import StrOutputParser # å¤„ç†æ¨¡å‹è¾“å‡ºç»“æœçš„è§£æå™¨
from langchain.prompts import PromptTemplate # åˆ›å»ºæ–‡æœ¬æ¨¡æ¿
from langchain.chains import RetrievalQA # åˆ›å»ºæ£€ç´¢å‹é—®ç­”é“¾
import sys
from zhipuai_embedding import ZhipuAIEmbeddings # ZhipuAIçš„åµŒå…¥æ¨¡å‹ï¼Œå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
from langchain.vectorstores.chroma import Chroma # å‘é‡æ•°æ®åº“ï¼Œå­˜å‚¨å’Œæ£€ç´¢æ–‡æœ¬æ•°æ®
from langchain.memory import ConversationBufferMemory # ç»˜ç”»è®°å¿†ç®¡ç†ï¼Œè·Ÿè¸ªç”¨æˆ·ä¸åŠ©æ‰‹çš„å¯¹è¯å†å²
from langchain.chains import ConversationalRetrievalChain # æ”¯æŒå¸¦è®°å¿†çš„æ£€ç´¢å‹é—®ç­”é“¾
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv())    # read local .env file
from zhipuai_llm import ZhipuAILLM
from datetime import datetime
# ä»ç¯å¢ƒå˜é‡è¯»å– API å¯†é’¥ï¼Œå¯ä»¥é¿å…æ³„éœ²
api_key = os.getenv('ZHIPUAI_API_KEY')  # ä½¿ç”¨ os.getenv() è·å–ç¯å¢ƒå˜é‡

# ç”Ÿæˆå›ç­”çš„å‡½æ•°
def generate_response(input_text, api_key):
    llm = ZhipuAILLM(model="glm-4", temperature=0.7, api_key=api_key) # è¿™é‡Œä½¿ç”¨glm-4æ¨¡å‹
    output = llm.invoke(input_text)
    output_parser = StrOutputParser()  # è§£ææ¨¡å‹çš„è¾“å‡ºï¼Œè¿”å›æœ€ç»ˆçš„æ–‡æœ¬ç­”æ¡ˆ
    output = output_parser.invoke(output)
    return output

# å¤„ç†æ–‡æœ¬æ•°æ®
def get_vectordb():
    # å®šä¹‰ Embedding
    embedding = ZhipuAIEmbeddings()

    # æœ¬åœ°è·¯å¾„
    persist_directory = '../data_base/vector_db/chroma'

    # å°è¯•åŠ è½½å·²æœ‰çš„æ•°æ®åº“ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»º
    if os.path.exists(persist_directory):
        vectordb = Chroma(
            persist_directory=persist_directory,
            embedding_function=embedding
        )
    else:
        # è¯»å–æ–‡æœ¬æ–‡ä»¶
        with open("æ¶ˆè´¹è€…æƒç›Šä¿æŠ¤æ³•.txt", "r", encoding="utf-8") as f:
            knowledge_base = f.readlines()  # è¯»å–æ‰€æœ‰è¡Œï¼Œå½¢æˆä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯è¡Œæ˜¯ä¸€ä¸ªæ®µè½æˆ–æ–‡æœ¬å—
        
        # æ¸…ç†æ•°æ®
        knowledge_base = [line.strip() for line in knowledge_base if line.strip()]  

        # åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“å¹¶æ·»åŠ æ•°æ®
        vectordb = Chroma(
            persist_directory=persist_directory,
            embedding_function=embedding
        )
        vectordb.add_texts(knowledge_base)

    return vectordb

# åˆå§‹åŒ–å¯¹è¯è®°å¿†ç®¡ç†
def init_memory():  # åˆå§‹åŒ–å¯¹è¯çš„è®°å¿†ç®¡ç†ç³»ç»Ÿ
    memory = ConversationBufferMemory(
        memory_key="chat_history",  # ä¸ prompt çš„è¾“å…¥å˜é‡ä¿æŒä¸€è‡´ã€‚
        return_messages=True  # èŠå¤©è®°å½•çš„è¿”å›ï¼šæ¶ˆæ¯åˆ—è¡¨ï¼Œæ–¹ä¾¿è¿½æº¯æ¯ä¸€è½®çš„ç”¨æˆ·è¾“å…¥å’Œæ¨¡å‹çš„å›ç­”
    )
    return memory  


# å¸¦æœ‰å†å²è®°å½•çš„é—®ç­”é“¾ï¼Œç»“åˆå†å²ã€å¤§æ¨¡å‹å’Œæ•°æ®åº“æ£€ç´¢ç”Ÿæˆå›ç­”
def get_chat_qa_chain(question: str, api_key: str, memory: ConversationBufferMemory):
    vectordb = get_vectordb() # è·å–å‘é‡æ•°æ®åº“
    llm = ZhipuAILLM(model="glm-4", temperature=0.1, api_key=api_key) # å°è£…çš„ZhipuAILLM

    retriever = vectordb.as_retriever() # åŸºäºå‘é‡ç›¸ä¼¼ï¼Œæ£€ç´¢æ•°æ®åº“ä¸­çš„ç›¸å…³æ–‡æœ¬
    # åˆ›å»ºé—®ç­”é“¾
    qa = ConversationalRetrievalChain.from_llm(  # é—®ç­”é“¾
        llm, # æä¾›çš„è¯­è¨€æ¨¡å‹ï¼Œç”Ÿæˆå›ç­”
        retriever = retriever, # æ£€ç´¢
        memory = memory # è®°å¿†
    )
    result = qa({"question": question})  # å°†ç”¨æˆ·é—®é¢˜ä¼ ç»™é—®ç­”é“¾
    return result['answer']


# ä¸å¸¦å†å²è®°å½•çš„é—®ç­”é“¾ï¼Œä½¿ç”¨æ–‡æ¡£å’Œå¤§æ¨¡å‹
def get_qa_chain(question: str, api_key: str):
    vectordb = get_vectordb()
    llm = ZhipuAILLM(model="glm-4", temperature=0.1, api_key=api_key)
    # æ„å»ºæ¨¡æ¿ï¼Œéœ€è¦ä»æ–‡æ¡£ä¸­æ‰¾ç­”æ¡ˆï¼Œæ²¡æœ‰æ‰¾åˆ°ç­”æ¡ˆï¼Œä½¿ç”¨è‡ªèº«çš„çŸ¥è¯†å›ç­”ï¼Œå¹¶å‘Šè¯‰ç”¨æˆ·
    # åœ¨ä¸Šä¸€æ®µä»£ç ä¸­ï¼Œå¹¶ä¸éœ€è¦æ„å»ºè¿™æ ·çš„æ¨¡æ¿ï¼Œå› ä¸ºConversationBufferMemoryå·²ç»æä¾›äº†æ¨¡æ¿
    template = "ä»ä»¥ä¸‹æ–‡æ¡£ä¸­è·å–ä¿¡æ¯ï¼Œå›ç­”é—®é¢˜ï¼š\n\"\"\"\n{context}\n\"\"\"\né—®é¢˜æ˜¯ï¼š\n\"\"\"\n{question}\n\"\"\"\nè¯·å°½é‡åªä½¿ç”¨æ–‡æ¡£ä¸­çš„ç›´æ¥ä¿¡æ¯æ¥å›ç­”ï¼Œé¿å…æ¨æµ‹ã€‚"
    QA_CHAIN_PROMPT = PromptTemplate(input_variables=["context", "question"],
                                 template=template)
    # åˆ›å»ºé—®ç­”é“¾
    qa_chain = RetrievalQA.from_chain_type(llm,
                                           retriever=vectordb.as_retriever(), # æ£€ç´¢
                                           return_source_documents=True,  # è¿”å›æ˜¯å“ªä¸ªæ–‡æ¡£
                                           chain_type_kwargs={"prompt": QA_CHAIN_PROMPT}) # æ ¹æ®æ¨¡æ¿æ ¼å¼åŒ–è¾“å‡º
    result = qa_chain({"query": question})
    return result["result"]


# streamlit
def main():
    st.title('æ³•æŠ¤é€š - æ³•å¾‹æ´åŠ©')

    # æ£€æŸ¥æ˜¯å¦è·å–åˆ° API å¯†é’¥
    if not api_key:
        st.error("Error - Please input correct API.")
        return

    # --- åˆå§‹åŒ–ä¼šè¯å­˜å‚¨ ---
    today = datetime.now().strftime("%Y-%m-%d")  # è·å–å½“å‰æ—¥æœŸ
    if 'daily_sessions' not in st.session_state:
        st.session_state.daily_sessions = {}  # æ¯å¤©å­˜å‚¨æ‰€æœ‰ä¼šè¯
    if today not in st.session_state.daily_sessions:
        st.session_state.daily_sessions[today] = []  # åˆå§‹åŒ–å½“å¤©çš„è®°å½•

    # åˆå§‹åŒ–æ‘˜è¦å­˜å‚¨
    if 'session_titles' not in st.session_state:
        st.session_state.session_titles = {}  # å­˜å‚¨æ¯ä¸ªå¯¹è¯çš„æ ‡é¢˜

    # --- æ–°å»ºå¯¹è¯æŒ‰é’® ---
    st.sidebar.title("ğŸ“‹ å¯¹è¯è®°å½•")
    if st.sidebar.button("æ–°å»ºå¯¹è¯"):
        # åˆ›å»ºä¸€ä¸ªæ–°å¯¹è¯
        new_title = f"æ–°å¯¹è¯ {len(st.session_state.daily_sessions[today]) + 1}"
        st.session_state.daily_sessions[today].append([])  # æ·»åŠ æ–°çš„ç©ºå¯¹è¯
        if today not in st.session_state.session_titles:
            st.session_state.session_titles[today] = []
        st.session_state.session_titles[today].append(new_title)

    # --- ä¾§è¾¹æ ï¼šæ˜¾ç¤ºå¯¹è¯æ ‡é¢˜ ---
    titles = st.session_state.session_titles.get(today, [])
    if titles:  # æ˜¾ç¤ºå½“å¤©çš„æ‰€æœ‰å¯¹è¯æ ‡é¢˜
        selected_title = st.sidebar.radio("é€‰æ‹©å¯¹è¯", titles)
        selected_index = titles.index(selected_title)
    else:
        selected_title, selected_index = None, -1

    # --- æ¨¡å¼é€‰æ‹© ---
    selected_method = st.radio(
        "æ‚¨è¦é€‰æ‹©ä»€ä¹ˆæ ·çš„æ£€ç´¢é—®ç­”æ–¹å¼",
        ["None", "qa_chain", "chat_qa_chain"],
        captions=["ä¸ä½¿ç”¨RAGçš„æ™®é€šæ¨¡å¼", "ä¸å¸¦å†å²è®°å½•çš„RAG", "å¸¦å†å²è®°å½•çš„RAG"]
    )

    # åˆå§‹åŒ–å½“å‰å¯¹è¯å†å²å’Œè®°å¿†
    if 'memory' not in st.session_state:
        st.session_state.memory = init_memory()

    # å½“å‰å¯¹è¯è®°å½•
    current_messages = []
    if selected_index != -1:  # å¦‚æœé€‰æ‹©äº†å†å²å¯¹è¯
        current_messages = st.session_state.daily_sessions[today][selected_index]

    # --- èŠå¤©çª—å£ ---
    st.subheader(f"å½“å‰å¯¹è¯ï¼š{selected_title or 'æ–°å¯¹è¯'}")
    messages = st.container(height=300)  # èŠå¤©å®¹å™¨

    # èŠå¤©è¾“å…¥æ¡†
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜"):
        # è®°å½•ç”¨æˆ·è¾“å…¥
        if selected_index == -1:  # æ–°å¯¹è¯
            current_messages = [{"role": "user", "text": prompt}]  # åˆå§‹åŒ–å½“å‰å¯¹è¯è®°å½•
            st.session_state.daily_sessions[today].append(current_messages)

            # è®¾ç½®å¯¹è¯æ ‡é¢˜ä¸ºç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
            title = prompt  # ä½¿ç”¨ç”¨æˆ·çš„ç¬¬ä¸€æ¡æ¶ˆæ¯ä½œä¸ºæ ‡é¢˜
            if today not in st.session_state.session_titles:
                st.session_state.session_titles[today] = []
            st.session_state.session_titles[today].append(title)
        else:  # æ›´æ–°å·²æœ‰å¯¹è¯
            current_messages.append({"role": "user", "text": prompt})

        # ç”Ÿæˆå›ç­”
        if selected_method == "None":
            answer = generate_response(prompt, api_key)
        elif selected_method == "qa_chain":
            answer = get_qa_chain(prompt, api_key)
        elif selected_method == "chat_qa_chain":
            answer = get_chat_qa_chain(prompt, api_key, st.session_state.memory)

        # è®°å½•åŠ©æ‰‹å›å¤
        if answer:
            current_messages.append({"role": "assistant", "text": answer})

        # æ›´æ–°å½“å¤©çš„è®°å½•
        if selected_index == -1:  # æ–°å¯¹è¯
            st.session_state.daily_sessions[today][-1] = current_messages
        else:  # æ›´æ–°å·²æœ‰å¯¹è¯
            st.session_state.daily_sessions[today][selected_index] = current_messages

        # æ˜¾ç¤ºå½“å‰å¯¹è¯
        for msg in current_messages:
            if msg["role"] == "user":
                messages.chat_message("user").write(msg["text"])
            elif msg["role"] == "assistant":
                messages.chat_message("assistant").write(msg["text"])

if __name__ == "__main__":
    main()
